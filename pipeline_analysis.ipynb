{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Data Science 4 Covid19': analysis of testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UC Sistemas Inteligentes para a BioinformÃ¡tica 20 | 21\n",
    "\n",
    "Group 4: \n",
    "> Carina Afonso PG40952 <br>\n",
    "> Laura Duro PG40959 <br>\n",
    "> Miguel Rocha PG40967 <br> \n",
    "> Miguel Martins PG40969 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Work contextualization and data description\n",
    "\n",
    "The Covid19 pandemic has been widely studied across several fields due to its large scale effects globally. More than 1.5 million people have died due to health complications caused by SARS-CoV-2 infection, since the final months of 2019. \n",
    "\n",
    "To figth this pandemic countries have been deploying different aproaches, namely testing policies. In this effort, we propose to analyse and explore the official testing data available for different countries. We aim to relate this information (tests wise) with other variables (demographic descriptors and pandemic related information) trough computacional methods such as machine and deep learning.\n",
    "\n",
    "The data chosen for this work was retrieved from 'Our World in Data': https://ourworldindata.org/coronavirus-testing [1]. It comprises of a time series, updated around twice a week, with mostly numeric data from official sources from 111 countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Libraries required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset - covid-19 testing data\n",
    "data_imported = pd.read_csv('owid-covid-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Inicial data screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:\t (60671, 50) \n",
      "\n",
      "Columns: ['iso_code' 'continent' 'location' 'date' 'total_cases' 'new_cases'\n",
      " 'new_cases_smoothed' 'total_deaths' 'new_deaths' 'new_deaths_smoothed'\n",
      " 'total_cases_per_million' 'new_cases_per_million'\n",
      " 'new_cases_smoothed_per_million' 'total_deaths_per_million'\n",
      " 'new_deaths_per_million' 'new_deaths_smoothed_per_million'\n",
      " 'reproduction_rate' 'icu_patients' 'icu_patients_per_million'\n",
      " 'hosp_patients' 'hosp_patients_per_million' 'weekly_icu_admissions'\n",
      " 'weekly_icu_admissions_per_million' 'weekly_hosp_admissions'\n",
      " 'weekly_hosp_admissions_per_million' 'total_tests' 'new_tests'\n",
      " 'total_tests_per_thousand' 'new_tests_per_thousand' 'new_tests_smoothed'\n",
      " 'new_tests_smoothed_per_thousand' 'positive_rate' 'tests_per_case'\n",
      " 'tests_units' 'stringency_index' 'population' 'population_density'\n",
      " 'median_age' 'aged_65_older' 'aged_70_older' 'gdp_per_capita'\n",
      " 'extreme_poverty' 'cardiovasc_death_rate' 'diabetes_prevalence'\n",
      " 'female_smokers' 'male_smokers' 'handwashing_facilities'\n",
      " 'hospital_beds_per_thousand' 'life_expectancy' 'human_development_index'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Shape:\\t', data_imported.shape, '\\n')\n",
    "print('Columns:', data_imported.columns.values, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trough the analysis of the presented variables in the dataset, we decided to remove the ones that presented no interest to the proposed task (testing analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:\t (60671, 46) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop columns with no interest\n",
    "data_imported.columns\n",
    "data_imported = data_imported.drop(columns = ['cardiovasc_death_rate', \n",
    "                                              'diabetes_prevalence', \n",
    "                                              'female_smokers',\n",
    "                                              'male_smokers'])\n",
    "\n",
    "print('Shape:\\t', data_imported.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iso_code                               object\n",
       "continent                              object\n",
       "location                               object\n",
       "date                                   object\n",
       "total_cases                           float64\n",
       "new_cases                             float64\n",
       "new_cases_smoothed                    float64\n",
       "total_deaths                          float64\n",
       "new_deaths                            float64\n",
       "new_deaths_smoothed                   float64\n",
       "total_cases_per_million               float64\n",
       "new_cases_per_million                 float64\n",
       "new_cases_smoothed_per_million        float64\n",
       "total_deaths_per_million              float64\n",
       "new_deaths_per_million                float64\n",
       "new_deaths_smoothed_per_million       float64\n",
       "reproduction_rate                     float64\n",
       "icu_patients                          float64\n",
       "icu_patients_per_million              float64\n",
       "hosp_patients                         float64\n",
       "hosp_patients_per_million             float64\n",
       "weekly_icu_admissions                 float64\n",
       "weekly_icu_admissions_per_million     float64\n",
       "weekly_hosp_admissions                float64\n",
       "weekly_hosp_admissions_per_million    float64\n",
       "total_tests                           float64\n",
       "new_tests                             float64\n",
       "total_tests_per_thousand              float64\n",
       "new_tests_per_thousand                float64\n",
       "new_tests_smoothed                    float64\n",
       "new_tests_smoothed_per_thousand       float64\n",
       "positive_rate                         float64\n",
       "tests_per_case                        float64\n",
       "tests_units                            object\n",
       "stringency_index                      float64\n",
       "population                            float64\n",
       "population_density                    float64\n",
       "median_age                            float64\n",
       "aged_65_older                         float64\n",
       "aged_70_older                         float64\n",
       "gdp_per_capita                        float64\n",
       "extreme_poverty                       float64\n",
       "handwashing_facilities                float64\n",
       "hospital_beds_per_thousand            float64\n",
       "life_expectancy                       float64\n",
       "human_development_index               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type of data per variable of interest\n",
    "data_imported.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Tests_units (variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different countries might have different methods of registering data and/or reported their data in different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries per test type:\n",
      "tests_units\n",
      "people tested       5446\n",
      "samples tested      5060\n",
      "tests performed    16500\n",
      "units unclear        588\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "Entries distribution per countries:\n",
      "\n",
      "iso_code         ARE  AUS  AUT  BEL  BGD  BGR  BHR  BLR  BOL  BRA  ...  TUR  \\\n",
      "tests_units                                                        ...        \n",
      "people tested      0    0    0    0    0    0    0    0    0    0  ...    0   \n",
      "samples tested     0    0    0    0    0    0    0    0    0    0  ...    0   \n",
      "tests performed  310  257  284  277  276  238    0  266  264   97  ...  249   \n",
      "units unclear      0    0    0    0    0    0  275    0    0    0  ...    0   \n",
      "\n",
      "iso_code         TWN  UGA  UKR  URY  USA  VNM  ZAF  ZMB  ZWE  \n",
      "tests_units                                                   \n",
      "people tested    323    0    0    0    0    0  294    0    0  \n",
      "samples tested     0  170    0    0    0  156    0    0    0  \n",
      "tests performed    0    0  240  251  275    0    0  260  211  \n",
      "units unclear      0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[4 rows x 111 columns] \n",
      "\n",
      "\n",
      "Number of countries per test type:\n",
      "tests_units\n",
      "people tested      20.0\n",
      "samples tested     21.0\n",
      "tests performed    67.0\n",
      "units unclear       3.0\n",
      "dtype: float64 \n",
      "\n",
      "Total of countries: 111.0 \n",
      "\n",
      "\n",
      "Missing values\n",
      "Null: 33077 \tNaN: 33077 \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), slice(None, None, None))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-399-ced1b9ad0b70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Null:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnull\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\tNaN:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mfreq_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2893\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), slice(None, None, None))' is an invalid key"
     ]
    }
   ],
   "source": [
    "#see test units\n",
    "print('Number of entries per test type:')\n",
    "print(data_imported.groupby(['tests_units']).size(), '\\n\\n')\n",
    "\n",
    "#frequency table per countries\n",
    "freq_table = pd.crosstab(index = data_imported['tests_units'], columns = data_imported['iso_code'])\n",
    "print('Entries distribution per countries:\\n')\n",
    "print(freq_table, '\\n\\n')\n",
    "print('Number of countries per test type:')\n",
    "print((freq_table/freq_table).sum(axis = 1), '\\n')\n",
    "print('Total of countries:', ((freq_table/freq_table).sum(axis = 1)).sum(), '\\n\\n')\n",
    "\n",
    "#check for missing values\n",
    "null = data_imported.iloc[:, 33].isnull().sum()\n",
    "na = data_imported.iloc[:, 33].isna().sum()\n",
    "print('Missing values')\n",
    "print('Null:', null, '\\tNaN:', na, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AtenÃ§Ã£o: falta explicar a cena do world e internacional -> nos 111 aquilo conta iso code e o world tem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing how countries are distributed based on the tests_units variable we decided to use only data from dataset entries which reported the number of tests and not the number of people tested. We also decided to discard dataset entries without defined units.\n",
    "\n",
    "We also checked for missing values (wich in this case correspond to null values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drop Nan\n",
    "data_imported = data_imported.dropna(subset = ['tests_units'])\n",
    "\n",
    "print('Missing values')\n",
    "na = data_imported.iloc[:, 33].isna().sum()\n",
    "print('NaN:', na, '\\n\\n')\n",
    "\n",
    "\n",
    "#drop countries with odd units\n",
    "countries_discard = pd.concat(objs = (freq_table.loc['units unclear'][freq_table.loc['units unclear'][:] != 0], \n",
    "                                      freq_table.loc['people tested'][freq_table.loc['people tested'][:] != 0]))\n",
    "countries_discard.keys()\n",
    "\n",
    "#discard internacional data\n",
    "index_discard = np.concatenate([data_imported['location'][data_imported['location'] == 'International'].keys().values,\n",
    "                                data_imported['location'][data_imported['location'] == 'World'].keys().values])\n",
    "#discard countries without standardized testing\n",
    "for code in countries_discard.keys().values:\n",
    "    index_discard = np.concatenate([index_discard,\n",
    "                                    data_imported['iso_code'][data_imported['iso_code'] == code].keys().values])\n",
    "\n",
    "screened_data = data_imported.drop(index = index_discard)\n",
    "    \n",
    "#frequency table per countries\n",
    "freq_table = pd.crosstab(index = screened_data['tests_units'], columns = screened_data['iso_code'])\n",
    "print('Number of countries per test type:')\n",
    "print((freq_table/freq_table).sum(axis = 1), '\\n')\n",
    "print('Total of countries:', ((freq_table/freq_table).sum(axis = 1)).sum(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, 88 countries reported testing data in a similar way and further analysis will be conducted for these countries (we will be considering the number of tests performed / samples tested, not the number of people tested)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Other testing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#NaN shit\n",
    "#screened_data['total_cases']\n",
    "\n",
    "print('Null:')\n",
    "null = screened_data.iloc[:, 4:32].isnull().sum()\n",
    "print(null, '\\n')\n",
    "print('Total:\\t', null.sum(), '\\n\\n')\n",
    "print('NaN:')\n",
    "na = screened_data.iloc[:, 4:32].isna().sum()\n",
    "print(na, '\\n')\n",
    "print('Total:\\t', na.sum(), '\\n\\n')\n",
    "\n",
    "screened_data.iloc[:, 4:32] = screened_data.iloc[:, 4:32].fillna(0)\n",
    "\n",
    "print('NaN:')\n",
    "na = screened_data.iloc[:, 4:32].isna().sum()\n",
    "print(na, '\\n')\n",
    "print('Total:\\t', na.sum(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitution of missing values of these pandemic related variables with 0 (when reported as a missing value, in these variables, it means there was no information on that entry regarding that variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [1]  Hasell, J., Mathieu, E., Beltekian, D. et al. A cross-country database of COVID-19 testing. Sci Data 7, 345 (2020)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
